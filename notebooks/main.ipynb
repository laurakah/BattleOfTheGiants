{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battle of the Giants\n",
    "### An exploration of the Kaggle Data Science and Machine Learning Survey  2019 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inviting pandas and friends to the party\n",
    "import pandas as pd, numpy as np\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\") # set seaborn styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing the raw data\n",
    "df = pd.read_csv(\"../data_raw/multiple_choice_responses_2019.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop questions\n",
    "df = df.drop(df.index[0])\n",
    "\n",
    "# check for and drop duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# dropping columns based on string pattern\n",
    "drop_all = [\"Q26\", \"Time from Start to Finish\", \"Q11\", \"Q19\"]\n",
    "\n",
    "for col in drop_all:\n",
    "    df = df.loc[:,~df.columns.str.contains(col)]\n",
    "\n",
    "# rename columns for better readability\n",
    "rename = {\"Q1\" : \"age\",\n",
    "          \"Q2\" : \"gender\",\n",
    "          \"Q3\" : \"country\",\n",
    "          \"Q4\" : \"degree\",\n",
    "          \"Q5\" : \"position\",\n",
    "          \"Q6\" : \"company_size\",\n",
    "          \"Q10\": \"salary\"\n",
    "          }\n",
    "df = df.rename(columns=rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing 2017 and 2018 datasets for comparison\n",
    "\n",
    "# import 2017\n",
    "df_2017 = pd.read_csv(\"../data_raw/multipleChoiceResponses_2017.csv\", engine='python')\n",
    "\n",
    "# drop duplicates\n",
    "df_2017 = df_2017.drop_duplicates()\n",
    "\n",
    "# rename columns\n",
    "rename_2017 = {\"Age\" : \"age\",\n",
    "                \"GenderSelect\" : \"gender\",\n",
    "                \"Country\" : \"country\",\n",
    "                \"FormalEducation\" : \"degree\",\n",
    "                \"EmployerSize\" : \"company size\",\n",
    "                \"LearningDataScienceTime\" : \"experience\",\n",
    "                \"CompensationAmount\" : \"salary\",\n",
    "                \"CompensationCurrency\" : \"currency\",\n",
    "                }\n",
    "\n",
    "# select columns\n",
    "df_2017 = df_2017[list(rename_2017.keys())]\n",
    "\n",
    "# rename columns\n",
    "df_2017 = df_2017.rename(columns=rename_2017)\n",
    "\n",
    "# select countries\n",
    "df_2017 = df_2017[(df_2017[\"country\"] == \"India\") | (df_2017[\"country\"] == \"United States\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 2018\n",
    "df_2018 = pd.read_csv(\"../data_raw/multipleChoiceResponses_2018.csv\", low_memory=False)\n",
    "\n",
    "# drop duplicates\n",
    "df_2018 = df_2018.drop_duplicates()\n",
    "\n",
    "# rename columns\n",
    "rename_2018 = {\"Q2\" : \"age\",\n",
    "                \"Q1\" : \"gender\",\n",
    "                \"Q3\" : \"country\",\n",
    "                \"Q4\" : \"degree\",\n",
    "                \"Q8\" : \"experience\",\n",
    "                \"Q9\" : \"salary\",\n",
    "                }\n",
    "# select columns\n",
    "df_2018 = df_2018[list(rename_2018.keys())]\n",
    "\n",
    "# rename columns\n",
    "df_2018 = df_2018.rename(columns=rename_2018)\n",
    "\n",
    "# select countries\n",
    "df_2018 = df_2018[(df_2018[\"country\"] == \"India\") | (df_2018[\"country\"] == \"United States of America\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating seperate dataframes for India and the US to make normalization more easy\n",
    "india = df[df[\"country\"] == \"India\"]\n",
    "usa = df[df[\"country\"] == \"United States of America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating comparison dataframe containing both India and the US\n",
    "df_comp = df[(df[\"country\"] == \"India\") | (df[\"country\"] == \"United States of America\")].copy()\n",
    "df_country_comp = df_comp[[\"country\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the survey results: A comparison between India and the US\n",
    "Since over the last three years the top two countries with the highest amount of responses for the Kaggle User Survey stayed the same we decided to take a closer look at these two lone giants in Data Science: the United States of America as a leading IT nation and India as a rapidly developing tech country.\n",
    "\n",
    "Can we see a trend in Indias position in the Data Science world?\n",
    "Are we able to make assumptions on the role of India regarding the use and development of Data Science?\n",
    "Is a new generation of Data Scientist going to come from India?\n",
    "\n",
    "And are the US a stable Data Science nation?\n",
    "Did they reach their full potential on Data Science yet or are there signs of change?\n",
    "\n",
    "<b>Please note</b> that when we talk about people from India and people from the US we mean the participants of the Kaggle User Survey 2019 (or 2018/2017 when labeled so) who stated that they currently live in India or the US respectively.\n",
    "We do not assume that this survey is representative to the US or the Indian population or Data Science community generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation functions\n",
    "\n",
    "# function to reverse dummy valiables based on column string pattern for whole dataframe\n",
    "# may return list of unique values when labels_only is set to True\n",
    "\n",
    "def undummy(df, col_pattern, labels_only=False):\n",
    "    df_tmp = df.loc[:,df.columns.str.contains(col_pattern)]\n",
    "    cols_to_bool = list(df_tmp.columns)\n",
    "\n",
    "    df_tmp = df_tmp.fillna(0)\n",
    "\n",
    "    labels = []\n",
    "    for col in cols_to_bool:\n",
    "        labels.append(df_tmp[col].value_counts().keys()[1])\n",
    "\n",
    "\n",
    "    for col in cols_to_bool:\n",
    "        df_tmp[col] = np.where(df_tmp[col] != 0, 1, 0)\n",
    "        df_tmp[col] = df_tmp[col].astype(int)\n",
    "\n",
    "    resources = []\n",
    "    for col in cols_to_bool:\n",
    "        resources.append(df_tmp[col].sum())\n",
    "\n",
    "    labels\n",
    "\n",
    "    resources = pd.DataFrame(data=resources, index=labels)\n",
    "    resources = resources.rename(columns={0: \"value\"})\n",
    "    resources = resources.sort_values(by=\"value\", ascending=False)\n",
    "    \n",
    "    if labels_only == True:\n",
    "        return labels\n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reverse dummy valiables based on column string pattern for single column\n",
    "\n",
    "def undummy_single_col(df, col_name):\n",
    "    sr_tmp = df[col_name]\n",
    "    sr_tmp = sr_tmp.fillna(0)\n",
    "\n",
    "    labels = sr_tmp.value_counts().keys().tolist()\n",
    "    labels = pd.Series(labels).astype(str)\n",
    "    labels = labels.str.replace(\"0\", \"None\")\n",
    "\n",
    "    resources = sr_tmp.value_counts().tolist()\n",
    "    \n",
    "    resources = pd.DataFrame(data=resources, index=labels)\n",
    "    resources = resources.rename(columns={0: \"value\"})\n",
    "    resources = resources.sort_values(by=\"value\", ascending=False)\n",
    "\n",
    "    return resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for calculating value percentages within given column\n",
    "def perc(df, col):\n",
    "    return round(100 * df[col].value_counts(normalize=True),2).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for normalizing value distribution within given column for both India and the US\n",
    "# return dataframe containing normalized values for given columns\n",
    "def total_to_perc(df, df1, df2, col1, col2):\n",
    "    df_perc = df.copy()\n",
    "    df_perc = df_perc.drop(columns=[col1, col2])\n",
    "    df_perc = df_perc.assign(india = df[col1].apply(lambda x: (x/len(df1))*100))\n",
    "    df_perc = df_perc.assign(usa = df[col2].apply(lambda x: (x/len(df2))*100))\n",
    "    return df_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global plotting variables\n",
    "\n",
    "# global figure size to use in the plots\n",
    "figure_size = (12,6)\n",
    "\n",
    "colors_pie_3 = [\"yellowgreen\", \"coral\", \"cornflowerblue\"]\n",
    "colors_pie_2 = [\"coral\", \"cornflowerblue\"]\n",
    "colors_bar_3 = [\"cornflowerblue\", \"coral\", \"yellowgreen\"]\n",
    "colors_bar_2 = [\"cornflowerblue\", \"coral\"]\n",
    "\n",
    "colors_years_2_in = [\"peachpuff\", \"coral\"]\n",
    "colors_years_2_us = [\"lightsteelblue\", \"cornflowerblue\"]\n",
    "colors_years_3_in = [\"peachpuff\", \"coral\", \"sienna\"]\n",
    "colors_years_3_us = [\"lightsteelblue\", \"cornflowerblue\", \"royalblue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Demographical exploration\n",
    "## 1.1 Answer ratio by country\n",
    "In this analysis we are only interested in answers from two distinct countries: India and the US.\n",
    "Let's have a look at the ratio of the answers from people who live in India and the answers from people who live in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting global survey participant ratio by country (countries other than India and US are aggregated in\n",
    "# \"Other countries\")\n",
    "\n",
    "labels = [\"Other countries\", \"India\", \"US\"]\n",
    "sizes = [len(df), len(india), len(usa)]\n",
    "colors = colors_pie_3\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=figure_size)\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90, colors=colors)\n",
    "ax1.axis('equal')\n",
    "ax1.set_title(\"India / USA as a subset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting ratio of survey participants for India and the US\n",
    "\n",
    "labels = df_country_comp[\"country\"].value_counts().keys().tolist()\n",
    "sizes = [len(india), len(usa)]\n",
    "colors = colors_pie_2\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=figure_size)\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=False, startangle=90, colors=colors_pie_2)\n",
    "ax1.axis('equal')\n",
    "ax1.set_title(\"India / US Proportion 2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Together India and the US make around 28.5% of all answers to the Kaggle User Survey 2019\n",
    "* We can see a 60/40 ratio for answers from India versus answers from the US\n",
    "\n",
    "### Conclusions:\n",
    "* In order to compare different features of Indian and American Data Scientists we will need to normalize values since the samples are not equal in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Answer ratio by country over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes for India and the US for the years 2017 and 2018\n",
    "india_2017 = df_2017[df_2017[\"country\"] == \"India\"]\n",
    "usa_2017 = df_2017[df_2017[\"country\"] == \"United States\"]\n",
    "india_2018 = df_2018[df_2018[\"country\"] == \"India\"]\n",
    "usa_2018 = df_2018[df_2018[\"country\"] == \"United States of America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting ratio of participants from India and the US over the last three years\n",
    "\n",
    "labels = [\"India\", \"US\"]\n",
    "\n",
    "sizes17 = [len(india_2017), len(usa_2017)]\n",
    "sizes18 = [len(india_2018), len(usa_2018)]\n",
    "sizes19 = [len(india), len(usa)]\n",
    "colors = colors_pie_2\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_axes([.1, .3, 1, 1], aspect=1)\n",
    "ax1.pie(sizes17, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "ax2 = fig.add_axes([.8, .3, 1, 1], aspect=1)\n",
    "ax2.pie(sizes18, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "ax3 = fig.add_axes([1.5, .3, 1, 1], aspect=1)\n",
    "ax3.pie(sizes19, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "\n",
    "ax1.set_title(\"2017\")\n",
    "ax2.set_title(\"2018\")\n",
    "ax3.set_title(\"2019\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Gender ratio\n",
    "In tech we still encounter a significant difference in the ratio between men, females and other genders. We were interested in seeing if this ratio would be different between India and the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for plotting: combining gender distribution of India and the US in dataframe\n",
    "global_gender_dist = perc(df, \"gender\").rename(columns={\"gender\" : \"global\"})\n",
    "india_gender_dist = perc(india, \"gender\").rename(columns={\"gender\" : \"india\"})\n",
    "usa_gender_dist = perc(usa, \"gender\").rename(columns={\"gender\" : \"usa\"})\n",
    "\n",
    "df_gender = usa_gender_dist.merge(right=india_gender_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_gender= df_gender.merge(right=global_gender_dist, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting gender distribution\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "df_gender.plot(kind=\"bar\", ax=ax, rot=45, color=colors_bar_3)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Gender Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "* While the gender ratio in India is quite similar to the global total ratio the gender ratio in the US shows that there are more answers from people described themselves as women and less from people who described themselves as men in comparison to the global gender ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Age distribution\n",
    "Let's have a look at the age distribution in India, in the US and globally in comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing age dataframes\n",
    "global_age_dist = perc(df, \"age\").rename(columns={\"age\" : \"global\"})\n",
    "india_age_dist = perc(india, \"age\").rename(columns={\"age\" : \"india\"})\n",
    "usa_age_dist = perc(usa, \"age\").rename(columns={\"age\" : \"usa\"})\n",
    "\n",
    "# merge age dataframes\n",
    "df_age = usa_age_dist.merge(right=india_age_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_age = df_age.merge(right=global_age_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_age = df_age.reset_index()\n",
    "df_age = df_age.rename(columns={\"index\": \"age\"}).sort_values(by=\"age\")\n",
    "df_age = df_age.set_index(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting age distribution\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "df_age.plot(kind=\"bar\", ax=ax, stacked=True, rot=45, color=colors_bar_3);\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Age Distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Compared to the global age distribution we can see that in India there is a higher percentage of young people between 18 and 29 years of age\n",
    "* Starting at the 30-34 years bucked there are lower and lower percentages for users from India\n",
    "* In comparison there are lower percentages for US than globally from young people between 18 and 24 years of age\n",
    "* Starting at the bucket of 25-29 years there are higher percentages for the US proportionally in comparison to the global age distribution\n",
    "\n",
    "### Conclusion\n",
    "* The age distribution shows that the majority of answers from Indian Kaggle users came from younger people under 30 while the majority of answers from US Kaggle users came from people in the middle age between 25 and 39\n",
    "* This may represent the age distribution of Data Scientists by country, the Kaggle user group by country or both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 Age distribution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data 2018\n",
    "age_in = (df_2018[df_2018[\"country\"]==\"India\"][\"age\"]\n",
    "           .value_counts(normalize=True)\n",
    "           .to_frame()\n",
    "           .rename(columns={\"age\" : \"2018\"}))\n",
    "age_us = (df_2018[df_2018[\"country\"]==\"United States of America\"][\"age\"]\n",
    "           .value_counts(normalize=True)\n",
    "           .to_frame()\n",
    "           .rename(columns={\"age\" : \"2018\"}))\n",
    "\n",
    "#get data 2019\n",
    "age_in = age_in.assign(age2019=df[df[\"country\"]==\"India\"][\"age\"].value_counts(normalize=True))\n",
    "age_in.rename(columns={\"age2019\" : \"2019\"}, inplace=True)\n",
    "\n",
    "age_us = age_us.assign(age2019=df[df[\"country\"]==\"United States of America\"][\"age\"].value_counts(normalize=True))\n",
    "age_us.rename(columns={\"age2019\" : \"2019\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting age distribution over time for US and India\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(18,8))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "data1 = age_in*100\n",
    "data2 = age_us*100\n",
    "ax1 = data1.plot(kind=\"bar\", ax=ax[0], grid=True, rot=45, colors=colors_years_3_in)\n",
    "ax2 = data2.plot(kind=\"bar\", ax=ax[1], grid=True, rot=45, colors=colors_years_3_us)\n",
    "ax1.set_title(\"Distribution of participants age (India)\")\n",
    "ax2.set_title(\"Distribution of participants age (USA)\")\n",
    "ax1.set_ylabel('Distribution [%]')\n",
    "ax2.set_ylabel('Distribution [%]')\n",
    "ax1.get_yticks()\n",
    "ax2.get_yticks();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Science in India and the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Highest educational degree\n",
    "Since the age distribution of survey participants from India versus participants from the US showed that Kaggle users from India on average are younger than Kaggle users from the US we had a look at the highest educational degree of the users to see if the age distribution reflects in the distribution of educational degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for educational degrees for US and India\n",
    "global_degree_dist = perc(df, \"degree\").rename(columns={\"degree\" : \"global\"})\n",
    "india_degree_dist = perc(india, \"degree\").rename(columns={\"degree\" : \"india\"})\n",
    "usa_degree_dist = perc(usa, \"degree\").rename(columns={\"degree\" : \"usa\"})\n",
    "\n",
    "df_degree = usa_degree_dist.merge(right=india_degree_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_degree = df_degree.merge(right=global_degree_dist, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting educational degrees for India and the US\n",
    "ax = df_degree.plot(kind=\"bar\", figsize=figure_size, rot=45, color=colors_bar_3);\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[3] = 'College/University study without degree'\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Educational Degree\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Percentage wise most people from India who answered to the Kaggle User Survey do have a Bachelor's degree followed by a Master's degree while Doctoral degrees do have lower percentages in the Indian sample\n",
    "* Answers from people from the US showed that the relative majority of American users does have a Master's degree\n",
    "\n",
    "### Conclusions:\n",
    "* Considering the age distribution of Indian and American contributions we assume that Indian participants on average do have slightly lower educational degrees than participants from the US because of their age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Highest educational degree over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data 2017\n",
    "degree_in = (df_2017[df_2017[\"country\"]==\"India\"][\"degree\"]\n",
    "           .value_counts(normalize=True)\n",
    "           .to_frame()\n",
    "           .rename(columns={\"degree\" : \"2017\"}))\n",
    "degree_us = (df_2017[df_2017[\"country\"]==\"United States\"][\"degree\"]\n",
    "           .value_counts(normalize=True)\n",
    "           .to_frame()\n",
    "           .rename(columns={\"degree\" : \"2017\"}))\n",
    "\n",
    "# uniform degrees \n",
    "replace_degree = {\"Bachelor's degree\" : \"Bachelor’s degree\",\n",
    "                  \"Master's degree\" : \"Master’s degree\",\n",
    "                  \"Some college/university study without earning a bachelor's degree\" : \"Some college/university study without earning a bachelor’s degree\",\n",
    "                  \"I did not complete any formal education past high school\" : \"No formal education past high school\",\n",
    "                 }\n",
    "degree_in.rename(index=replace_degree, inplace=True)\n",
    "degree_us.rename(index=replace_degree, inplace=True)\n",
    "\n",
    "# get data 2018\n",
    "degree_in = degree_in.assign(deg2018=df_2018[df_2018[\"country\"]==\"India\"][\"degree\"]\n",
    "                               .value_counts(normalize=True))\n",
    "degree_in.rename(columns={\"deg2018\" : \"2018\"}, inplace=True)\n",
    "degree_us = degree_us.assign(deg2018=df_2018[df_2018[\"country\"]==\"United States of America\"][\"degree\"]\n",
    "                               .value_counts(normalize=True))\n",
    "degree_us.rename(columns={\"deg2018\" : \"2018\"}, inplace=True)\n",
    "\n",
    "# get data 2019\n",
    "degree_in = degree_in.assign(deg2019=df[df[\"country\"]==\"India\"][\"degree\"]\n",
    "                               .value_counts(normalize=True))\n",
    "degree_in.rename(columns={\"deg2019\" : \"2019\"}, inplace=True)\n",
    "degree_us = degree_us.assign(deg2019=df[df[\"country\"]==\"United States of America\"][\"degree\"]\n",
    "                               .value_counts(normalize=True))\n",
    "degree_us.rename(columns={\"deg2019\" : \"2019\"}, inplace=True)\n",
    "\n",
    "# uniform degrees \n",
    "rename_values = {\"Some college/university study without earning a bachelor’s degree\" : \"Studied without earning degree\",\n",
    "                \"Bachelor’s degree\" : \"Bachelor\",\n",
    "                \"Master’s degree\" : \"Master\",\n",
    "                \"Professional degree\" : \"Professional\",\n",
    "                \"Doctoral degree\" : \"Doctor\",\n",
    "                \"No formal education past high school\" : \"No formal education\",\n",
    "                \"I prefer not to answer\" : \"No answer\"\n",
    "                }\n",
    "degree_us.rename(index=rename_values, inplace=True)\n",
    "degree_in.rename(index=rename_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder the index\n",
    "index_degree = (['Bachelor', 'Master', 'Doctor', 'Professional', 'Studied without earning degree', 'No formal education', 'No answer'])\n",
    "degree_us = degree_us.reindex(index_degree)\n",
    "degree_in = degree_in.reindex(index_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting educational degrees over time for US and India\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(18,8))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "data1 = degree_in*100\n",
    "data2 =data2 = degree_us*100\n",
    "ax1 = data1.plot(kind=\"bar\", ax=ax[0], grid=True, rot=45, colors=colors_years_3_in)\n",
    "ax2 = data2.plot(kind=\"bar\", ax=ax[1], grid=True, rot=45, colors=colors_years_3_us)\n",
    "ax1.set_title(\"Distribution of educational degree of participants (India)\")\n",
    "ax2.set_title(\"Distribution of educational degree of participants (USA)\")\n",
    "ax1.set_ylabel('Distribution [%]')\n",
    "ax2.set_ylabel('Distribution [%]')\n",
    "ax1.get_yticks()\n",
    "ax2.get_yticks();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Current job position\n",
    "After looking at the educational degrees let's have a look at the current position of the survey participants and see if our assumption of a relatively high percentage of students in India will be confirmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for job position names for India and the US\n",
    "global_position_dist = perc(df, \"position\").rename(columns={\"position\" : \"global\"})\n",
    "india_position_dist = perc(india, \"position\").rename(columns={\"position\" : \"india\"})\n",
    "usa_position_dist = perc(usa, \"position\").rename(columns={\"position\" : \"usa\"})\n",
    "\n",
    "df_position = usa_position_dist.merge(right=india_position_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_position = df_position.merge(right=global_position_dist, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_position.plot(kind=\"bar\", figsize=figure_size, rot=45, color=colors_bar_3)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Current Job Position\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Within the participants from the US \"Data Scientist\" is the most commonly chosen job description\n",
    "* Percentage wise most of the participants from India are currently students\n",
    "\n",
    "### Conclusions:\n",
    "* Indeed over one third of the participants from India are currently students. Since this is much more than the percentage of participants from India who stated to be without any educational degree we assume that many  students from India interested in Data Science are currently aming for a second degree, e.g. a Master's degree.\n",
    "* We assume that these students are going to finish their studies within the next years and become some great Data Scientists, Engineers, Analysts, etc. (or at least some of them is going to be!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Salary\n",
    "When looking at the proportion of educational degrees among India and the US we would expect to find a slightly different salary distribution in the US and India. Due to the high amount of students within the Indian participants we expect a higher percentage of people with a low income from India versus a higher percentage of people with a medium or high income in the US according to the high percentage of Master's degrees within the survey answers from the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for salary distribution within Data Science for India and the US\n",
    "global_salary_dist = perc(df, \"salary\").rename(columns={\"salary\" : \"global\"})\n",
    "india_salary_dist = perc(india, \"salary\").rename(columns={\"salary\" : \"india\"})\n",
    "usa_salary_dist = perc(usa, \"salary\").rename(columns={\"salary\" : \"usa\"})\n",
    "\n",
    "df_salary = usa_salary_dist.merge(right=india_salary_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_salary = df_salary.merge(right=global_salary_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_salary = df_salary.reset_index().rename(columns={\"index\" : \"salary\"}).sort_values(\"salary\").set_index(\"salary\")\n",
    "\n",
    "# reordering salaries\n",
    "df_salary = df_salary.reindex(index = [\"$0-999\", \"1,000-1,999\", \"2,000-2,999\",  \"3,000-3,999\", \"4,000-4,999\", \n",
    "                                       \"5,000-7,499\", \"7,500-9,999\", \"10,000-14,999\", \"15,000-19,999\", \"20,000-24,999\", \n",
    "                                       \"25,000-29,999\", \"30,000-39,999\", \"40,000-49,999\", \"50,000-59,999\", \n",
    "                                       \"60,000-69,999\", \"70,000-79,999\", \"80,000-89,999\", \"90,000-99,999\", \n",
    "                                       \"100,000-124,999\", \"125,000-149,999\", \"150,000-199,999\", \"200,000-249,999\",\n",
    "                                       \"250,000-299,999\", \"300,000-500,000\", \"> $500,000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_salary.plot(kind=\"line\", figsize=figure_size, rot=45, color=colors_bar_3)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Yearly Salary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Within the India sample there is a relatively high percentage of people with an income between 0 and 999 Dollars. Apart from that the most value accumulate around the 5.000 – 10.000 buckets.\n",
    "* Within the US sample there also is a moderate percentage of people with an income between 0 and 999 Dollars but this percentage is smaller than the percentage within the Indian sample. Apart from that the most values accumulate around the 100.000 and 150.000 Dollar buckets.\n",
    "\n",
    "### Conclusions:\n",
    "* We expected to find a relatively lower average income within the Indian sample - both due to the high percentage of students and the economical differences between India and the US. In fact we do find a significantly high amount of people with no or a really low income in India.\n",
    "* Within the group of survey participants from India the income of people with a regular income seems to accumulate around the 5.000 – 10.000 buckets which may be the mean average salary for Data Scientists in India. The higher the income is the lower the percentage within the Indian sample.\n",
    "* In the US respectively there is only a relatively small percentage of people with a really low income. The majority groups between 100.000 and 150.000 Dollars which is probably the mean regular salary of Data Scientist of any kind in the US.\n",
    "* This distribution fits our assumptions regarding the distribution of studying versus working Data Scientists within both samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Company size\n",
    "Looking at the potential of upcoming Data Scientists of any kind within India and the US we want to examine the current state of the DS industry in both our samples. Evaluating the company size offers insights on the exploitment of the potentials of DS across India and the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for company size distribution\n",
    "global_company_size_dist = perc(df, \"company_size\").rename(columns={\"company_size\" : \"global\"})\n",
    "india_company_size_dist = perc(india, \"company_size\").rename(columns={\"company_size\" : \"india\"})\n",
    "usa_company_size_dist = perc(usa, \"company_size\").rename(columns={\"company_size\" : \"usa\"})\n",
    "\n",
    "df_company_size = usa_company_size_dist.merge(right=india_company_size_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "df_company_size = df_company_size.merge(right=global_company_size_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# reordering index\n",
    "df_company_size = df_company_size.reset_index().rename(columns={\"index\" : \"company_size\"}).sort_values(\"company_size\").set_index(\"company_size\")\n",
    "df_company_size = df_company_size.reindex(index = [\"0-49 employees\", \"50-249 employees\", \"250-999 employees\", \"1000-9,999 employees\", \"> 10,000 employees\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_company_size.plot(kind=\"line\", figsize=figure_size, rot=45, color=colors_bar_3)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Company Size\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Compared to the US a higher percentage of small Indian companies with 1 – 250 employees applies DS methodology\n",
    "* Within the company size range between 1.000 and 9.999 employees more companies in the US use DS\n",
    "* In companies with more than 10.000 employees Indian companies take over again regarding the use of DS tools and methodology. \n",
    "\n",
    "### Conclusions:\n",
    "* Over all company sizes both India and the US do not vary a lot from the global distribution.\n",
    "* Higher percentages of people from India than from the US work in very small or very big companies applying any kind of Data Science. We can assume that quite small and quite big companies tend to apply Data Science more often than companies of middle size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tools and technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Programming languages\n",
    "We want to know if the tools and technologies used in the Data Science context differ between India and the US. The use of different programming languages could show trends and help young Data Scientists decide which languages to practice first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for the use of programming languages in India and the US\n",
    "languages_india = undummy(india, \"Q18\")\n",
    "languages_india = languages_india.drop(\"2\", axis=0)\n",
    "languages_india = languages_india.rename(index={0: \"Python\"})\n",
    "\n",
    "languages_usa = undummy(usa, \"Q18\")\n",
    "languages_usa = languages_usa.drop(\"2\", axis=0)\n",
    "languages_usa = languages_usa.rename(index={0: \"Python\"})\n",
    "\n",
    "# merging dataframes\n",
    "languages = languages_india.merge(right=languages_usa, how=\"inner\", left_index=True, right_index=True)\n",
    "languages = languages.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\n",
    "\n",
    "# normalizing\n",
    "languages_perc = total_to_perc(languages, india, usa, \"india\", \"usa\")\n",
    "languages_perc = languages_perc[['usa', 'india']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting programming languages percentages\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "languages_perc.plot(kind=\"bar\", ax=ax, rot=45, color=colors_bar_2)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of the Use of Programming Languages\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* Within both India and the US Python is the programming language most participants use\n",
    "* In the US higher percentages of programmers use SQL, R and Bash than in India\n",
    "* In India higher percentages of programmers use C++, C and Java than in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Programming experience\n",
    "The programming experience in years in conjunction with age and degree can be an indicator for the time the surveys participants have been interested in or practicing Data Science.\n",
    "Based on the results of the age and educational degree visualization we expect a high percentage of people from India with less programming experience and a more flat distribution for people in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for programming experience in India and the US\n",
    "india_exp_dist = perc(india, \"Q15\").rename(columns={\"Q15\": \"india\"})\n",
    "usa_exp_dist = perc(usa, \"Q15\").rename(columns={\"Q15\": \"usa\"})\n",
    "df_exp = usa_exp_dist.merge(right=india_exp_dist, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# reordering index\n",
    "df_exp = df_exp.reindex([\"I have never written code\", \"< 1 years\", \"1-2 years\", \"3-5 years\", \"5-10 years\", \"10-20 years\", \"20+ years\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting programming experience percentages\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "df_exp.plot(kind=\"line\", ax=ax, color=colors_bar_2)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Programming Experience in Years\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* We see higher percentages for shorter amounts of programming experience in years (< one year until 1 – 2 years) for participants in India. \n",
    "* For participants in the US we see a moderate increasing in percentages until the 3 – 5 years mark. After this point the percentages flatten slowly.\n",
    "\n",
    "### Conclusions:\n",
    "* As assumed the distribution of programming experience in years is similar to the age distribution for both India and the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning experience\n",
    "The machine learning experience in years can be an indicator for a digital transformation towards machine learning in the field of Data Science.\n",
    "Similar to the programming experience in years we assume a high percentage of people from India having a shorter machine learning experience in comparison to people from the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for machine learning experience in India and the US\n",
    "india_exp_ml_dist = perc(india, \"Q23\").rename(columns={\"Q23\": \"india\"})\n",
    "usa_exp_ml_dist = perc(usa, \"Q23\").rename(columns={\"Q23\": \"usa\"})\n",
    "df_exp_ml = usa_exp_ml_dist.merge(right=india_exp_dist, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting machine learning experience percentages\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "df_exp_ml.plot(kind=\"line\", ax=ax, color=colors_bar_2)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of Machine Learning Experience in Years\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* We see a high percentage of Indian participants with machine learning experience between less than one year and 1 – 2 years\n",
    "* In comparison the distribution of machine learning experience of participants from the US is more flat and more equally distributed between < one year and 20+ years\n",
    "\n",
    "### Conclusions:\n",
    "* As assumed there is a high percentage of people from India with a lower amount of machine learning experience fitting the age and degree distribution for people from India\n",
    "* Other than the programming experience almost 50% of participants from India seem to have started learning about machine learning within the last year. This may be an indicator for a growing interest towards machine learning in India and this topic being part of educational programs of Indian students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Machine learning algorithms\n",
    "Based on the observations regarding programming and machine learning experience of the survey participants we wanted to know if there are any differences in the distribution of machine learning algorithms between India and the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for machine learning algorithms used in India and the US\n",
    "ml_tools_india = undummy(india, \"Q24\")\n",
    "ml_tools_india = ml_tools_india.rename(index={0: \"Linear or Logistic Regression\"})\n",
    "ml_tools_usa = undummy(usa, \"Q24\")\n",
    "ml_tools_usa = ml_tools_usa.rename(index={0: \"Linear or Logistic Regression\"})\n",
    "\n",
    "ml_tools = ml_tools_india.merge(right=ml_tools_usa, how=\"inner\", left_index=True, right_index=True)\n",
    "ml_tools = ml_tools.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\n",
    "ml_tools = ml_tools.drop(\"1\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_tools_perc = total_to_perc(ml_tools, india, usa, \"india\", \"usa\")\n",
    "ml_tools_perc = ml_tools_perc[['usa', 'india']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting machine learning algorithms percentage\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "ml_tools_perc.plot(kind=\"bar\", ax=ax, color=colors_bar_2)\n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of the Use of Machine Learning Algorithms\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* We see that for almost all algorithms a slightly higher percentage of participants from the US stated to use these in comparison to participants from India\n",
    "* The only exception are Convolutional Neural Network algorithms - a slightly higher percentage of participants from India seem to use these\n",
    "\n",
    "### Conclusions:\n",
    "* We are not surprised to see lower percentages for most machine learning algorithms in India than in the US since we saw that many participants from India are still in the process of learning about Data Science. \n",
    "* Since the machine learning experience of participants from the US is longer on average these participants of course had more time to practice and apply different types of ML algorithms e.g. in their jobs.\n",
    "* The distribution of the regular application of these machine learning algorithms can also relate to the educational degree and age of the participants: With growing age and education the experience with ML algorithms on a regular basis increases in the field of Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Learning Resources\n",
    "Last but not least we wanted to know which resources participants use to learn about Data Science related topics - especially since we saw that a high percentage of participants from India are currently students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataframes for Data Science learning resources used in India and the US\n",
    "resources_india = undummy(india, \"Q13\")\n",
    "resources_usa = undummy(usa, \"Q13\")\n",
    "\n",
    "resources = resources_india.merge(right=resources_usa, how=\"inner\", left_index=True, right_index=True)\n",
    "resources = resources.rename(columns={\"value_x\": \"india\", \"value_y\": \"usa\"})\n",
    "\n",
    "resources_perc = total_to_perc(resources, india, usa, \"india\", \"usa\")\n",
    "\n",
    "resources_perc = resources_perc[['usa', 'india']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting learning resources percentages\n",
    "fig, ax = plt.subplots(figsize=figure_size)\n",
    "resources_perc.plot(kind=\"bar\", ax=ax, color=colors_bar_2)   \n",
    "ax.set_ylabel('Distribution [%]')\n",
    "ax.set_title(\"Distribution of the Use of Learning Resources\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "* The most popular learning resource among both participants from India and the US seems to be Coursera\n",
    "* We see bigger differences in the percentages for participants from India and the US in the use of \"Other\" learning resorces as well as learning within University Courses\n",
    "\n",
    "### Conclusions:\n",
    "* Surprisingly round double the percentage of participants from the US stated to learn through University Courses compared to participants from India. This may mean that even though a higher percentage of Indian participants interested in Data Science is currently studying at university not all of these students study a topic related to Data Science.\n",
    "* Due to the difference in the student/employed ratio and the ratio of people who learn from University Courses versus people who learn from online resources we assume that a significantly amount of Indian students learn about Data Science online while studying a different topic. This may be an indicator for the assumption that Data Science is of growing importance in different industries in India."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
